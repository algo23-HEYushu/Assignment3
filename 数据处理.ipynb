{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d839908-6c49-4bcc-8dc8-655c36375088",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据过大，且文档格式为某一只股票在一段时间内的5分钟k线数据，所以分批读入；\n",
    "2017年年末到2022年年末，5年时间一共调整了21次中证1000成分股，手动5次读取数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ce85d7-37a9-4d7f-9426-e6ce8014a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd17a2d-3178-422b-8fd1-d9086d4b7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置数据储存位置\n",
    "read_path=r'I:\\PG\\QInvestment\\project\\zz1000_5min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6068724-08e1-4100-a46e-f4c26c2c2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入数据储存地址\n",
    "def getPathTime(path):\n",
    "    allpaths=[]\n",
    "    timelist=[]\n",
    "    files=os.listdir(path)\n",
    "    for file_path in files:\n",
    "        temptime=file_path[10:-3]\n",
    "        new_path=os.path.join(path,file_path)\n",
    "        timelist.append(temptime)\n",
    "        allpaths.append(new_path)\n",
    "    return allpaths,timelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53338afd-022a-431d-9206-c64871f26cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_read_path,timelist=getPathTime(read_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7cccf0b-9e05-44ff-b789-4fb497ba3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按时间读入数据，用数据框查看多少个时间段\n",
    "df_timelist=pd.DataFrame(timelist)\n",
    "timeNums=df_timelist.drop_duplicates().sort_values(by=0).reset_index(drop=True)\n",
    "datelist=df_timelist.drop_duplicates().sort_values(by=0)[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7c0d22-ec25-454d-86cd-ada5b012d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_list = locals()#获取当前位置前的全部局部变量\n",
    "grouplist=[]\n",
    "for ii in range(timeNums.shape[0]):\n",
    "    groupname='group'+str(ii+1)\n",
    "    grouplist.append(groupname)\n",
    "    prepare_list[groupname]=[]\n",
    "    for path in all_read_path:\n",
    "        if datelist[ii] in path:\n",
    "            prepare_list[groupname].append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963a86b8-6fec-4098-9283-f3fe5f38037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataframe(paths):#paths是列表\n",
    "    dfsum=pd.DataFrame(data=None)\n",
    "    for path in paths:\n",
    "        tempdata=pd.read_parquet(path,columns=['date','time','code','high','low'],engine='auto')\n",
    "        dfsum=pd.concat([dfsum,tempdata])\n",
    "    return dfsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a53aaf2d-2c34-4506-ae42-093a1a55122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#以时间分21组，每组1000个函数，读取数据21次\n",
    "#数据太大手动拆分,分5批读入\n",
    "prepare_df_list = locals()#获取当前位置前的全部局部变量\n",
    "data_name_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd66b2a-3228-4172-99ab-7cec64a5e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取前4组\n",
    "for ii in range(4):\n",
    "    dataname='data'+str(ii+1)\n",
    "    data_name_list.append(dataname)\n",
    "    prepare_df_list[dataname]=pd.DataFrame(getDataframe(prepare_list[grouplist[ii]]))#变量名是列表元素，不代表储存值的列表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd1ea4-df95-4cde-8344-506853583639",
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取5-8组\n",
    "#for ii in np.arange(4,8,1):\n",
    " #   dataname='data'+str(ii+1)\n",
    "  #  data_name_list.append(dataname)\n",
    "   # prepare_df_list[dataname]=pd.DataFrame(getDataframe(prepare_list[grouplist[ii]]))#变量名是列表元素，不代表储存值的列表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381acea9-c273-4d22-8893-9cb043445433",
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取9-12组\n",
    "#for ii in np.arange(8,12,1):\n",
    " #   dataname='data'+str(ii+1)\n",
    " #   data_name_list.append(dataname)\n",
    " #   prepare_df_list[dataname]=pd.DataFrame(getDataframe(prepare_list[grouplist[ii]]))#变量名是列表元素，不代表储存值的列表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26fa7f-85ec-43cf-a2e5-3c4a5e733a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取13-18组\n",
    "#for ii in np.arange(12,18,1):\n",
    " #   dataname='data'+str(ii+1)\n",
    " #   data_name_list.append(dataname)\n",
    " #   prepare_df_list[dataname]=pd.DataFrame(getDataframe(prepare_list[grouplist[ii]]))#变量名是列表元素，不代表储存值的列表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3675a-1b81-4e93-b1bd-de163b54f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取19-21组\n",
    "\n",
    "#for ii in np.arange(18,21,1):\n",
    " #   dataname='data'+str(ii+1)\n",
    "  #  data_name_list.append(dataname)\n",
    "   # prepare_df_list[dataname]=pd.DataFrame(getDataframe(prepare_list[grouplist[ii]]))#变量名是列表元素，不代表储存值的列表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6a8405-c4fc-4898-a457-11337462f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理时间\n",
    "def timeProcess(data):\n",
    "    tempdata=data.reset_index(drop=True)\n",
    "    tempdata['time']=tempdata['time'].apply(lambda x:x[8:12])#变为0935 4位格式\n",
    "    return tempdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0123ec7b-25b5-4bc0-98ca-833ccd1bb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉前15分钟以及最后15分钟的数据\n",
    "def dropData15(data):   \n",
    "    #前15分钟\n",
    "    index1=data[(data['time']=='0935') | (data['time']=='0940') | (data['time']=='0945')].index.tolist()\n",
    "    #后15分钟\n",
    "    index2=data[(data['time']=='1445') | (data['time']=='1450') | (data['time']=='1455') | (data['time']=='1500')].index.tolist()\n",
    "    index=index1+index2\n",
    "    data1=data.drop(index)\n",
    "    data1=data1.reset_index(drop=True)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144c1c1c-d4e7-4492-8e04-0f5bf8ba1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到日内波动率\n",
    "def Parkinson(data):\n",
    "    timelist=[]\n",
    "    codelist=[]\n",
    "    timeStampNum=np.array(data.groupby(['date','code']).count()['time'])#日内时间点为41\n",
    "    tempcol=np.array(data.groupby(['date','code']).count()['time'].index)\n",
    "    data.iloc[:,-3:]=data.iloc[:,-3:].astype(float)#将low/high/close转为float\n",
    "    data['highLowDaily']=data['high']/data['low']\n",
    "    data['highLowDaily']=data['highLowDaily'].apply(lambda x: math.log(x,math.e))\n",
    "    data['highLowDaily']=data['highLowDaily'].apply(lambda x: x**2)\n",
    "    temp_variance=np.array(data.groupby(['date','code']).sum()['highLowDaily'])\n",
    "    parkinsonV=(temp_variance/(4*timeStampNum*math.log(2,math.e)))**0.5\n",
    "    for ii in tempcol:\n",
    "        timelist.append(ii[0])\n",
    "        codelist.append(ii[1])\n",
    "    data_v=pd.DataFrame({'date':timelist,\n",
    "                         'code':codelist,\n",
    "                         'variance':parkinsonV})\n",
    "    return data_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916e1067-5a6b-4ab3-9a31-b5230387f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023格式不同\n",
    "def Parkinson1(data):\n",
    "    timelist=[]\n",
    "    codelist=[]\n",
    "    timeStampNum=np.array(data.groupby(['date','code']).count()['time'])#日内时间点为41\n",
    "    tempcol=np.array(data.groupby(['date','code']).count()['time'].index)\n",
    "    data.iloc[:,-2:]=data.iloc[:,-2:].astype(float)#将low/high/close转为float\n",
    "    data['highLowDaily']=data['high']/data['low']\n",
    "    data['highLowDaily']=data['highLowDaily'].apply(lambda x: math.log(x,math.e))\n",
    "    data['highLowDaily']=data['highLowDaily'].apply(lambda x: x**2)\n",
    "    temp_variance=np.array(data.groupby(['date','code']).sum()['highLowDaily'])\n",
    "    parkinsonV=(temp_variance/(4*timeStampNum*math.log(2,math.e)))**0.5\n",
    "    for ii in tempcol:\n",
    "        timelist.append(ii[0])\n",
    "        codelist.append(ii[1])\n",
    "    data_v=pd.DataFrame({'date':timelist,\n",
    "                         'code':codelist,\n",
    "                         'variance':parkinsonV})\n",
    "    return data_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe798718-7416-4fa3-aebe-b14ac2cc7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对日内波动率进行标准化处理\n",
    "def standardProcess(dataV):\n",
    "    meanDaily=dataV.groupby(['date']).mean()['variance']\n",
    "    stdDaily=dataV.groupby(['date']).std()['variance']\n",
    "    tempDaily=pd.concat([meanDaily,stdDaily],axis=1,keys=['mean','varianceDaily'])\n",
    "    standVariance=dataV.merge(tempDaily,on='date',how='left')\n",
    "    dataV['variance']=(standVariance['variance']-standVariance['mean'])/standVariance['varianceDaily']\n",
    "    return dataV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b5910f4-5e01-4dd0-827d-6447b7e3446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\3306785750.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_variance=np.array(data.groupby(['date','code']).sum()['highLowDaily'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  meanDaily=dataV.groupby(['date']).mean()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  stdDaily=dataV.groupby(['date']).std()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\3306785750.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_variance=np.array(data.groupby(['date','code']).sum()['highLowDaily'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  meanDaily=dataV.groupby(['date']).mean()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  stdDaily=dataV.groupby(['date']).std()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\3306785750.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_variance=np.array(data.groupby(['date','code']).sum()['highLowDaily'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  meanDaily=dataV.groupby(['date']).mean()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  stdDaily=dataV.groupby(['date']).std()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\3306785750.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_variance=np.array(data.groupby(['date','code']).sum()['highLowDaily'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  meanDaily=dataV.groupby(['date']).mean()['variance']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10572\\1052861444.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  stdDaily=dataV.groupby(['date']).std()['variance']\n"
     ]
    }
   ],
   "source": [
    "#组合每一批计算得到的日内波动率\n",
    "datagroup=pd.DataFrame(data=None)\n",
    "for dataname in data_name_list:\n",
    "    tempdata=timeProcess(prepare_df_list[dataname])\n",
    "    tempdata1=dropData15(tempdata)\n",
    "    parkinsonData=Parkinson1(tempdata1)\n",
    "    dataStandardV=standardProcess(parkinsonData)\n",
    "    datagroup=pd.concat([datagroup,dataStandardV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c03b4de7-4d6d-4ef1-86c9-0c94de3b9d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#手动验证5分钟K线数据是否有缺失值\n",
    "tempdata1.shape[0]/parkinsonData.shape[0]#是否为41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cab5e3-736c-436e-84f5-706eebb989fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#手动写入文件\n",
    "datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup1.csv')\n",
    "#datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup2.csv')\n",
    "#datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup3.csv')\n",
    "#datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup4.csv')\n",
    "#datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4fd46-e6dc-4e6b-b8f9-da55636d079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取2023年数据\n",
    "read_path1=r'I:\\PG\\QInvestment\\project\\zz1000_5min_high_low_2023'\n",
    "data2023=pd.read_parquet(read_path1,engine='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9c540-9f78-4544-8531-419e143510bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#单独计算2023年\n",
    "tempdata=timeProcess(data2023)\n",
    "tempdata1=dropData15(tempdata)\n",
    "parkinsonData=Parkinson1(tempdata1)\n",
    "datagroup=standardProcess(parkinsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21e7fa-3d26-4915-9577-0b7ad2cb8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bc944-aa9d-4044-bcf0-8f4f56a57faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#单独计算2017年12月前40天数据\n",
    "read_path2=r'I:\\PG\\QInvestment\\project\\zz1000_5min_high_low_2017.pq'\n",
    "data2017=pd.read_parquet(read_path2,engine='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595be04b-4fea-4c35-ba90-9acc314c812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata=timeProcess(data2017)\n",
    "tempdata1=dropData15(tempdata)\n",
    "parkinsonData=Parkinson(tempdata1)\n",
    "datagroup=standardProcess(parkinsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30f1eb-05a0-4f30-8e82-e4caca1907c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagroup.to_csv('I:\\PG\\QInvestment\\project\\datagroup0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
